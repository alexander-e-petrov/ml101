{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to ML101 Welcome to our training! In this training we'll be using the Cloud Pak for Data platform to Collect Data, Organize Data, Analyze Data, and Infuse AI into our applications. About this training In this training you will be learning the basics of ML through IBM Cloud Pak for Data. Agenda Topic Description Type General Introduction ML101 Introduction Lecture Platform Overview Cloud Pak for Data overview Lecture Incident Resolution with AutoAI Predict incident resolution time using AutoAI Hands-on lab Unstructured Data Analysis on R Studio Use RStudio to train an LDA model based on pubmed data Hands-on lab Breast Tumor Classification Train a custom model using Jupyter notebooks Hands-on lab","title":"About the training"},{"location":"#welcome-to-ml101","text":"Welcome to our training! In this training we'll be using the Cloud Pak for Data platform to Collect Data, Organize Data, Analyze Data, and Infuse AI into our applications.","title":"Welcome to ML101"},{"location":"#about-this-training","text":"In this training you will be learning the basics of ML through IBM Cloud Pak for Data.","title":"About this training"},{"location":"#agenda","text":"Topic Description Type General Introduction ML101 Introduction Lecture Platform Overview Cloud Pak for Data overview Lecture Incident Resolution with AutoAI Predict incident resolution time using AutoAI Hands-on lab Unstructured Data Analysis on R Studio Use RStudio to train an LDA model based on pubmed data Hands-on lab Breast Tumor Classification Train a custom model using Jupyter notebooks Hands-on lab","title":"Agenda"},{"location":"resources/","text":"Documents and Resources by Section","title":"Resources"},{"location":"resources/#documents-and-resources-by-section","text":"","title":"Documents and Resources by Section"},{"location":"autoai/","text":"Predict Incident Resolution Time with AutoAI Brief introduction... About the data set This data set contains incidents reported through ServiceNow since October 2020. incident.csv This CSV file contains incident dimension data. Field Description Type number Incident unique identifier String caller_id.employee_number Employee ID of the caller used to get the profile String u_on_behalf_of.employee_number Environment provisioning and setup String location Caller location address automatically added based on their profile. Can be modified based on the current location of the caller String u_floor Floor automatically added based on caller profile. Can be modified based on the current location of the caller String u_room Room automatically added based on caller profile. Can be modified based on the current location of the caller String category Used to categorize the incident. Examples: Hardware , Software , Inquiry/Help , etc. String subcategory The selected category define the options available for the subcategory . Examples: Clinical System , Access , etc. String business_service String cmdb_ci Impacted device String contact_type Defines the method the incident originated. Examples: Phone , Virtual Agent , etc. String parent String state Defines the lifecycle stage of the incident. Examples: In Progress , Resolved , Closed , etc. All incidents start at New String impact Defines the number of affected people or locations String urgency Defines how quickly the incident should be resolved String priority Provides guidance related to the sequence in which incidents need to be resolved and is automatically calculated based on impact and urgency selections String assignment_group Used to determine who will work on the incident String assigned_to When and individual is designated the assigned_to (not required to submit an incident), the incident moves to the state In Progress String short_description Used to describe the incident reported. May contain PHI String description Used to expand on the short_description . It should be used to add context to the issue reported. May contain PHI String close_code Resolution code. Example: Solved (Permanently) , Closed/Resolved by Caller String close_notes Resolution information. Defines what was done to resolve the incident String resolved_by.employee_number Employee ID that resolved the issue String resolved_at Time when the issues was marked as resolved Timestamp work_notes Updates to the form String incident_sla.csv Data extracted from the incident SLA fact table. Field Description Type inc_number Incident unique identifier. Can be used to join incident.number String taskslatable_sla Indicates response or resolution associated SLA String taskslatable_stage Define the lifecycle stage of the incident String taskslatable_has_breached Indicates if the response time has exceeded the SLA Boolean inc_business_duration Work time for the incident to be resolved in seconds Number inc_calendar_duration Calendar time for the incident to be resolved in seconds Number taskslatable_schedule Work schedule assigned to the incident String taskslatable_start_time Incident start time Timestamp taskslatable_end_time Incident end time Timestamp","title":"Introduction"},{"location":"autoai/#predict-incident-resolution-time-with-autoai","text":"Brief introduction...","title":"Predict Incident Resolution Time with AutoAI"},{"location":"autoai/#about-the-data-set","text":"This data set contains incidents reported through ServiceNow since October 2020.","title":"About the data set"},{"location":"autoai/#incidentcsv","text":"This CSV file contains incident dimension data. Field Description Type number Incident unique identifier String caller_id.employee_number Employee ID of the caller used to get the profile String u_on_behalf_of.employee_number Environment provisioning and setup String location Caller location address automatically added based on their profile. Can be modified based on the current location of the caller String u_floor Floor automatically added based on caller profile. Can be modified based on the current location of the caller String u_room Room automatically added based on caller profile. Can be modified based on the current location of the caller String category Used to categorize the incident. Examples: Hardware , Software , Inquiry/Help , etc. String subcategory The selected category define the options available for the subcategory . Examples: Clinical System , Access , etc. String business_service String cmdb_ci Impacted device String contact_type Defines the method the incident originated. Examples: Phone , Virtual Agent , etc. String parent String state Defines the lifecycle stage of the incident. Examples: In Progress , Resolved , Closed , etc. All incidents start at New String impact Defines the number of affected people or locations String urgency Defines how quickly the incident should be resolved String priority Provides guidance related to the sequence in which incidents need to be resolved and is automatically calculated based on impact and urgency selections String assignment_group Used to determine who will work on the incident String assigned_to When and individual is designated the assigned_to (not required to submit an incident), the incident moves to the state In Progress String short_description Used to describe the incident reported. May contain PHI String description Used to expand on the short_description . It should be used to add context to the issue reported. May contain PHI String close_code Resolution code. Example: Solved (Permanently) , Closed/Resolved by Caller String close_notes Resolution information. Defines what was done to resolve the incident String resolved_by.employee_number Employee ID that resolved the issue String resolved_at Time when the issues was marked as resolved Timestamp work_notes Updates to the form String","title":"incident.csv"},{"location":"autoai/#incident_slacsv","text":"Data extracted from the incident SLA fact table. Field Description Type inc_number Incident unique identifier. Can be used to join incident.number String taskslatable_sla Indicates response or resolution associated SLA String taskslatable_stage Define the lifecycle stage of the incident String taskslatable_has_breached Indicates if the response time has exceeded the SLA Boolean inc_business_duration Work time for the incident to be resolved in seconds Number inc_calendar_duration Calendar time for the incident to be resolved in seconds Number taskslatable_schedule Work schedule assigned to the incident String taskslatable_start_time Incident start time Timestamp taskslatable_end_time Incident end time Timestamp","title":"incident_sla.csv"},{"location":"autoai/autoai/","text":"Automate model building with AutoAI In this module, we'll learn how to use AutoAI . The AutoAI tool is a capability that automates various tasks to ease the workflow for data scientists that are creating machine learning models. AutoAI automatically analyzes your data and generates candidate model pipelines customized for your predictive modeling problem. These model pipelines are created iteratively as AutoAI analyzes your dataset and discovers data transformations, algorithms, and parameter settings that work best for your problem setting. This section is broken up into the following steps: Run AutoAI Experiment Save and Promote AutoAI Model Save AutoAI Notebooks Conclusion Note: You can click on any image in the instructions below to zoom in and see more details. When you do that just click on your browser's back button to return to the previous page. Create an AutoAI Experiment Go the (\u2630) navigation menu, expand Projects and click on the project you created during the setup section. To start the AutoAI experiment, click the Add to project + button from the top of the page and select the AutoAI experiment option. Give the AutoAI experiment any name you like. The associated Watson Machine Learning Service Instance should already be populated for you. If not, please select the one that you created in the setup section from the drop down. Then click the Create button. To configure the experiment, we must first give it the dataset that will be used to train the machine learning model. Click on the Select from project button to point to a dataset in your project. Now we can select the training CSV file. If you completed the previous Data Processing with Data Refinery lab module where you generated a single shaped CSV file from a refinery job, select that CSV file (the name will be whatever you selected in that module, for example: incident_shaped.csv ). Now, we will need to indicate what we want the model to predict. Under What do you want to predict? panel, select the Prediction column as inc_business_duration . AutoAI will set up defaults values for the experiment based on the dataset and the column selected for the prediction. This includes the type of model to build, the metrics to optimize against, the test/train split, etc. To view/change these values, click the Experiment settings button. Click on the Data source tab. For the sake of time, in the Subsample section turn on Subsample rows switch and set the Amount to 10 percent. Scroll down to the Select features to include section. Deselect the checkbox for the number , taskslatable_sla , taskslatable_stage , inc_calendar_duration , taskslatable_start_time and taskslatable_end_time column names. This will remove these fields from being used as a feature for the model. Although we could change other aspects of the experiment, we will accept the remaining default values and click the Save settings button. ( Feel free to explore the other possible settings before clicking the save button ). To start the experiment, click on the Run experiment button. The AutoAI experiment will now run. AutoAI will run through steps to prepare the dataset, split the dataset into training / evaluation groups and then find the best performing algorithms / estimators for the type of model. It will then build the following series of candidate pipelines for each of the top N performing algorithms (where N is a number chosen in the configuration which defaults to 2): Baseline model (Pipeline 1) Hyperparameter optimization (Pipeline 2) Automated feature engineering (Pipeline 3) Hyperparameter optimization on top of engineered features (Pipeline 4) The UI will show progress as different algorithms/evaluators are selected and as different pipelines are created and evaluated. You can view the performance of the pipelines that have completed by expanding each pipeline section in the leaderboard. The experiment can take several minutes to complete. Upon completion you will see a message that the pipelines have been created. Do not proceed to the next section until the experiment completes. Save and Promote AutoAI Model Once the experiment completes, you can explore the various pipelines and options in the UI. Some of the options available are to see a comparison of the pipelines, to change the ranking based on a different performance metric, to see a log of the experiment, or to see the ranked listing of the pipelines (ranking based on the optimization metric in your experiment, in this case, RMSE). Scroll down to see the Pipeline leaderboard . The top performing pipeline is in the first rank. The next step is to select the model that gives the best result and view its performance. In this case, Pipeline 4 gave the best result for our experiment. You can view the detailed results by clicking the corresponding pipeline name from the leaderboard: The model evaluation page will show metrics for the experiment, feature transformations that were performed (if any), which features contribute to the model, and more details of the pipeline. Optionally, feel free to click through these views of the pipeline details. For instance, you could select Pipeline 2 (before the feature engineering step) and review the Feature Importance tab. You will notice that assignment_group is the on the top of this list In order to deploy this model, select Pipeline 4 , click on the Save as button. On the next scren, select the Model option. Keep the default name, add an optional description and tags, and click the Create button to save the model. You will see a notification to indicate that your model is saved to your project. Click the View in project link in the notification to go to the saved model. ( Alternatively, if you navigate back to your project assets tab by closing the pipeline and AutoAI experiment, you will see the saved model in the Models section, which you can click on to explore ). To make the model available to be deployed, we need to make it available in the deployment space you created during the setup module. Click on the Promote to deployment space : Select the deployment space that was created as part of the setup module as the Target space and click Promote . You will be brought back to your project assets page and see a notification that the model was promoted to the deployment space successfully. Feel free to close that notification. Conclusion Congratulation. We have now successfully created a highly optimized machine learning model using AutoAI and prepared it for deployment. In this section we covered one approach to building machine learning models on Cloud Pak for Data as a Service. We have seen how AutoAI helps to find an optimal model by automating tasks such as: Data Wrangling Algorithm Evaluation & Selection Feature Engineering Hyperparameter Optimization","title":"Model building with AutoAI"},{"location":"autoai/autoai/#automate-model-building-with-autoai","text":"In this module, we'll learn how to use AutoAI . The AutoAI tool is a capability that automates various tasks to ease the workflow for data scientists that are creating machine learning models. AutoAI automatically analyzes your data and generates candidate model pipelines customized for your predictive modeling problem. These model pipelines are created iteratively as AutoAI analyzes your dataset and discovers data transformations, algorithms, and parameter settings that work best for your problem setting. This section is broken up into the following steps: Run AutoAI Experiment Save and Promote AutoAI Model Save AutoAI Notebooks Conclusion Note: You can click on any image in the instructions below to zoom in and see more details. When you do that just click on your browser's back button to return to the previous page.","title":"Automate model building with AutoAI"},{"location":"autoai/autoai/#create-an-autoai-experiment","text":"Go the (\u2630) navigation menu, expand Projects and click on the project you created during the setup section. To start the AutoAI experiment, click the Add to project + button from the top of the page and select the AutoAI experiment option. Give the AutoAI experiment any name you like. The associated Watson Machine Learning Service Instance should already be populated for you. If not, please select the one that you created in the setup section from the drop down. Then click the Create button. To configure the experiment, we must first give it the dataset that will be used to train the machine learning model. Click on the Select from project button to point to a dataset in your project. Now we can select the training CSV file. If you completed the previous Data Processing with Data Refinery lab module where you generated a single shaped CSV file from a refinery job, select that CSV file (the name will be whatever you selected in that module, for example: incident_shaped.csv ). Now, we will need to indicate what we want the model to predict. Under What do you want to predict? panel, select the Prediction column as inc_business_duration . AutoAI will set up defaults values for the experiment based on the dataset and the column selected for the prediction. This includes the type of model to build, the metrics to optimize against, the test/train split, etc. To view/change these values, click the Experiment settings button. Click on the Data source tab. For the sake of time, in the Subsample section turn on Subsample rows switch and set the Amount to 10 percent. Scroll down to the Select features to include section. Deselect the checkbox for the number , taskslatable_sla , taskslatable_stage , inc_calendar_duration , taskslatable_start_time and taskslatable_end_time column names. This will remove these fields from being used as a feature for the model. Although we could change other aspects of the experiment, we will accept the remaining default values and click the Save settings button. ( Feel free to explore the other possible settings before clicking the save button ). To start the experiment, click on the Run experiment button. The AutoAI experiment will now run. AutoAI will run through steps to prepare the dataset, split the dataset into training / evaluation groups and then find the best performing algorithms / estimators for the type of model. It will then build the following series of candidate pipelines for each of the top N performing algorithms (where N is a number chosen in the configuration which defaults to 2): Baseline model (Pipeline 1) Hyperparameter optimization (Pipeline 2) Automated feature engineering (Pipeline 3) Hyperparameter optimization on top of engineered features (Pipeline 4) The UI will show progress as different algorithms/evaluators are selected and as different pipelines are created and evaluated. You can view the performance of the pipelines that have completed by expanding each pipeline section in the leaderboard. The experiment can take several minutes to complete. Upon completion you will see a message that the pipelines have been created. Do not proceed to the next section until the experiment completes.","title":"Create an AutoAI Experiment"},{"location":"autoai/autoai/#save-and-promote-autoai-model","text":"Once the experiment completes, you can explore the various pipelines and options in the UI. Some of the options available are to see a comparison of the pipelines, to change the ranking based on a different performance metric, to see a log of the experiment, or to see the ranked listing of the pipelines (ranking based on the optimization metric in your experiment, in this case, RMSE). Scroll down to see the Pipeline leaderboard . The top performing pipeline is in the first rank. The next step is to select the model that gives the best result and view its performance. In this case, Pipeline 4 gave the best result for our experiment. You can view the detailed results by clicking the corresponding pipeline name from the leaderboard: The model evaluation page will show metrics for the experiment, feature transformations that were performed (if any), which features contribute to the model, and more details of the pipeline. Optionally, feel free to click through these views of the pipeline details. For instance, you could select Pipeline 2 (before the feature engineering step) and review the Feature Importance tab. You will notice that assignment_group is the on the top of this list In order to deploy this model, select Pipeline 4 , click on the Save as button. On the next scren, select the Model option. Keep the default name, add an optional description and tags, and click the Create button to save the model. You will see a notification to indicate that your model is saved to your project. Click the View in project link in the notification to go to the saved model. ( Alternatively, if you navigate back to your project assets tab by closing the pipeline and AutoAI experiment, you will see the saved model in the Models section, which you can click on to explore ). To make the model available to be deployed, we need to make it available in the deployment space you created during the setup module. Click on the Promote to deployment space : Select the deployment space that was created as part of the setup module as the Target space and click Promote . You will be brought back to your project assets page and see a notification that the model was promoted to the deployment space successfully. Feel free to close that notification.","title":"Save and Promote AutoAI Model"},{"location":"autoai/autoai/#conclusion","text":"Congratulation. We have now successfully created a highly optimized machine learning model using AutoAI and prepared it for deployment. In this section we covered one approach to building machine learning models on Cloud Pak for Data as a Service. We have seen how AutoAI helps to find an optimal model by automating tasks such as: Data Wrangling Algorithm Evaluation & Selection Feature Engineering Hyperparameter Optimization","title":"Conclusion"},{"location":"autoai/data-refinery/","text":"Data Processing with Data Refinery In this module, we will prepare our data assets for analysis. We will use the Data Refinery graphical flow editor tool to create a set of ordered operations that will cleanse and shape our data. We will also explore the graphical interface to profile data and create visualizations to get a perspective and insights into the dataset. This section is broken up into the following steps: Merge and Cleanse Data Profile Data Visualize Data Note: You can click on any image in the instructions below to zoom in and see more details. When you do that just click on your browser's back button to return to the previous page. Merge and Cleanse Data We will start by wrangling, shaping and refining our data. To do this, we will create a refinery flow to contain a series of data transformation steps. Go the (\u2630) navigation menu, expand Projects and click on the AutoAIIncidentResolution project pre-created for this section. To create a data refinery flow, click the Add to project button from the top of the page and click the Data Refinery flow option. Select Data assets on the left panel, then select the incident.csv data asset. Then click the Add button. The first thing we want to do is create a merged dataset. Start by joining the incident data with information about incident SLA. Click the Operation + button on the top left and then scroll down and select the Join operation. From the drop down list, select Inner join and then click the Add data set link to select the data asset you are going to join with. Select Data assets on the left panel and this time select the incident_sla.csv data asset. Then click the Apply button. Finish setting the following values and then click the Next button: Under the Source *Suffix option, enter _inc_ds . Under the Data set to join *Suffix option, enter _inc_sla_ds . Under the Join keys, click the input box and select number for incident.csv and inc_number for incident_sla.csv . Although we could modify what columns will be in the joined dataset, we will leave the default and include them all. Click the Apply button. Now we want to filter the rows that will be used for training the model. Click on the Operation + button and select Filter operation. Use the condition CONDITION 1 and Under Column select taskslatable_sla and for Operator select Contains . Leaving the Text checkbox selected, type Resolve . Then add a second condition by clicking on Add condition + and leave AND selected. This time, under Column select taskslatable_stage and in Operator select Is equal to and type Completed on the Value text input field. Go ahead and click Apply . Finally, for visualization purposes, let's convert the inc_business_duration column from String to Integer . Again, click on Operation + button and select Convert column type . Click on Select column + and under Column select inc_business_duration . On Type select Integer and Apply . At this point, you have a data transformation flow with 3 steps. The flow keeps track of each of the steps and we can even undo (or redo) an action using the circular arrows. To see the steps in the data flow that you have performed, click the Steps button. The operations that you have performed on the data will be shown. You can modify these steps and/or save for future use. Lets edit the flow name and output options. Click on the Information icon on the top right and then click the Edit button. Click the pencil icon next to Data Refinery Flow Name , set the name to incident_cleaning_flow and click the Apply button. Then click the Edit Output pencil icon and set the name to incident_shaped.csv (leave the rest of the CSV output defaults) and click the 'Check mark icon'. Finally, click the Done button Click the Save icon to save the flow. Run Data Flow Job Data Refinery allows you to run these data flow jobs on demand or at scheduled times. In this way, you can regularly refine new data as it is updated. Click on the Jobs icon and then Save and create a job option from the menu. Give the job a name and optional description. Click the Next button. Click Next on the next two screens, leaving the default selections. You will reach the Review and create screen. Note the output name, which is incident_shaped.csv . Click the Create and run button. When the job is successfully created, you will receive a notification. Click on the job details link in the notification panel to see the job status. The job will be listed with a status of Running and then the status will change to Completed . Once its completed, click the project name AutoAIIncidentResolution . Click on the Assets and you will find a new CSV file incident_shaped.csv in your Data assets Profile Data Scroll down to the Data Refinery flows section and click on the incident_cleaning_flow flow. Wait for the flow operations to be applied and then click on the Profile tab will bring up a view of several statistics and histograms for the attributes in your data. You can get insight into the data from the views and statistics: The median incident business duration is 289 seconds. TODO: add more insights Visualize Data Let's do some visual exploration of our data using charts and graphs. Note that this is an exploratory phase and we're looking for insights in out data. We can accomplish this in Data Refinery interactively without coding. Scatter category / subcategory Histogram assignment_group Conclusion We've seen a some of the capabilities of the Data Refinery. We saw how we can transform data, as well as using various operations on the columns such as changing the data type and filtering. We next saw that all the steps in our Data Flow are recorded, so we can remove steps, repeat them, or edit an individual step. We were able to quickly profile the data, to see histograms and statistics for each column. And finally we created more in-depth Visualizations, creating a scatter plot and histogram to explore the relationship between the incident duration and its category, subcategory and assignment group.","title":"Data processing with Data Refinery"},{"location":"autoai/data-refinery/#data-processing-with-data-refinery","text":"In this module, we will prepare our data assets for analysis. We will use the Data Refinery graphical flow editor tool to create a set of ordered operations that will cleanse and shape our data. We will also explore the graphical interface to profile data and create visualizations to get a perspective and insights into the dataset. This section is broken up into the following steps: Merge and Cleanse Data Profile Data Visualize Data Note: You can click on any image in the instructions below to zoom in and see more details. When you do that just click on your browser's back button to return to the previous page.","title":"Data Processing with Data Refinery"},{"location":"autoai/data-refinery/#merge-and-cleanse-data","text":"We will start by wrangling, shaping and refining our data. To do this, we will create a refinery flow to contain a series of data transformation steps. Go the (\u2630) navigation menu, expand Projects and click on the AutoAIIncidentResolution project pre-created for this section. To create a data refinery flow, click the Add to project button from the top of the page and click the Data Refinery flow option. Select Data assets on the left panel, then select the incident.csv data asset. Then click the Add button. The first thing we want to do is create a merged dataset. Start by joining the incident data with information about incident SLA. Click the Operation + button on the top left and then scroll down and select the Join operation. From the drop down list, select Inner join and then click the Add data set link to select the data asset you are going to join with. Select Data assets on the left panel and this time select the incident_sla.csv data asset. Then click the Apply button. Finish setting the following values and then click the Next button: Under the Source *Suffix option, enter _inc_ds . Under the Data set to join *Suffix option, enter _inc_sla_ds . Under the Join keys, click the input box and select number for incident.csv and inc_number for incident_sla.csv . Although we could modify what columns will be in the joined dataset, we will leave the default and include them all. Click the Apply button. Now we want to filter the rows that will be used for training the model. Click on the Operation + button and select Filter operation. Use the condition CONDITION 1 and Under Column select taskslatable_sla and for Operator select Contains . Leaving the Text checkbox selected, type Resolve . Then add a second condition by clicking on Add condition + and leave AND selected. This time, under Column select taskslatable_stage and in Operator select Is equal to and type Completed on the Value text input field. Go ahead and click Apply . Finally, for visualization purposes, let's convert the inc_business_duration column from String to Integer . Again, click on Operation + button and select Convert column type . Click on Select column + and under Column select inc_business_duration . On Type select Integer and Apply . At this point, you have a data transformation flow with 3 steps. The flow keeps track of each of the steps and we can even undo (or redo) an action using the circular arrows. To see the steps in the data flow that you have performed, click the Steps button. The operations that you have performed on the data will be shown. You can modify these steps and/or save for future use. Lets edit the flow name and output options. Click on the Information icon on the top right and then click the Edit button. Click the pencil icon next to Data Refinery Flow Name , set the name to incident_cleaning_flow and click the Apply button. Then click the Edit Output pencil icon and set the name to incident_shaped.csv (leave the rest of the CSV output defaults) and click the 'Check mark icon'. Finally, click the Done button Click the Save icon to save the flow.","title":"Merge and Cleanse Data"},{"location":"autoai/data-refinery/#run-data-flow-job","text":"Data Refinery allows you to run these data flow jobs on demand or at scheduled times. In this way, you can regularly refine new data as it is updated. Click on the Jobs icon and then Save and create a job option from the menu. Give the job a name and optional description. Click the Next button. Click Next on the next two screens, leaving the default selections. You will reach the Review and create screen. Note the output name, which is incident_shaped.csv . Click the Create and run button. When the job is successfully created, you will receive a notification. Click on the job details link in the notification panel to see the job status. The job will be listed with a status of Running and then the status will change to Completed . Once its completed, click the project name AutoAIIncidentResolution . Click on the Assets and you will find a new CSV file incident_shaped.csv in your Data assets","title":"Run Data Flow Job"},{"location":"autoai/data-refinery/#profile-data","text":"Scroll down to the Data Refinery flows section and click on the incident_cleaning_flow flow. Wait for the flow operations to be applied and then click on the Profile tab will bring up a view of several statistics and histograms for the attributes in your data. You can get insight into the data from the views and statistics: The median incident business duration is 289 seconds. TODO: add more insights","title":"Profile Data"},{"location":"autoai/data-refinery/#visualize-data","text":"Let's do some visual exploration of our data using charts and graphs. Note that this is an exploratory phase and we're looking for insights in out data. We can accomplish this in Data Refinery interactively without coding. Scatter category / subcategory Histogram assignment_group","title":"Visualize Data"},{"location":"autoai/data-refinery/#conclusion","text":"We've seen a some of the capabilities of the Data Refinery. We saw how we can transform data, as well as using various operations on the columns such as changing the data type and filtering. We next saw that all the steps in our Data Flow are recorded, so we can remove steps, repeat them, or edit an individual step. We were able to quickly profile the data, to see histograms and statistics for each column. And finally we created more in-depth Visualizations, creating a scatter plot and histogram to explore the relationship between the incident duration and its category, subcategory and assignment group.","title":"Conclusion"},{"location":"autoai/wml/","text":"Machine Learning Model Online Deployment and Scoring In this module, we will learn how to deploy our Machine Learning models. By doing so, we make them available for use in production such that applications and business processes can derive insights from them. There are several types of deployments available ( depending on the model framework used ). In this lab, we will explore: Online Deployments - Allows you to run the model on data in real-time, as data is received by a web service. This lab will build an online deployment and test the model endpoint using both the built in testing tool as well as external testing tools. Note: You can click on any image in the instructions below to zoom in and see more details. When you do that just click on your browser's back button to return to the previous page. Create Online Model Deployment After a model has been created, saved and promoted to our deployment space, we can proceed to deploying the model. For this section, we will be creating an online deployment. This type of deployment will make an instance of the model available to make predictions in real time via an API. Although we will use the Cloud Pak for Data UI to deploy the model, the same can be done programmatically. Navigate to the left-hand (\u2630) hamburger menu, click on the Deployments section. Click on the Spaces tab and then choose the deployment space you setup previously by clicking on the name of your space. From your deployment space overview, click the Assets tab and in the Models table, find the model name for the model you previously built and now want to create a deployment against. Use your mouse to hover over the right side of that table row and click the Deploy rocket icon (the icons are not visible by default until you hover over them). On the Create a deployment screen, choose Online for the Deployment Type , give the Deployment a name and optionally a description and click the Create button. Click on the Deployments tab. The new deployment status will show as In progress and then switch to Deployed when it is complete. Test Online Model Deployment Cloud Pak for Data offers tools to quickly test out Watson Machine Learning models. We begin with the built-in tooling. From the Model deployment page, once the deployment status shows as Deployed , click on the name of your deployment. The deployment API reference tab shows how to use the model using cURL , Java , Javascript , Python , and Scala . To get to the built-in test tool, click on the Test tab and then click on the Provide input data as JSON icon. Copy and paste the following data objects into the Body panel (replace the text that was in the input panel). { \"input_data\": [ { \"fields\": [ \"number\", \"location\", \"u_floor\", \"u_room\", \"category\", \"subcategory\", \"business_service\", \"priority\", \"assignment_group\", \"taskslatable_sla\", \"taskslatable_stage\", \"inc_calendar_duration\", \"taskslatable_schedule\", \"taskslatable_start_time\", \"taskslatable_end_time\" ], \"values\": [ [ \"\", \"530 East 74th (Koch)\", \"16th Floor\", \"16-260\", \"Hardware\", \"Printer\", \"\", \"5 - Planning\", \"\", \"\", \"\", \"8-5 weekdays excluding holidays\", \"\", \"\" ] ] } ] } Click the Predict button. The model will be called with the input data and the results will display in the Result window. Scroll down to the bottom of the result to see the prediction. Note: For some deployed models (for example AutoAI based models), you can provide the request payload using a generated form by clicking on the Provide input using form icon and providing values for the input fields of the form. If the form is not available for the model you deployed, the icon will not be present or will remain grayed out. Important: If you have completed this section and do not plan on completing the other optional deployment approaches below, please go ahead and cleanup your deployment. Follow the Cleanup Deployment instructions below. Cleanup Deployments You can clean up the deployments created for your models. To remove the deployment: Navigate to the left-hand (\u2630) hamburger menu, expand the Deployments section and click on View all spaces . Choose the deployment space you setup previously by clicking on the name of your space. From your deployment space overview, click the Assets tab and in the 'Model' table, click on the model name that you previousely promoted and created deployments against. Under 'Deployment Types', click on Online to view the online deployments you have created for this model. In the table on the main panel, click on the three vertical dots at the right of the row for the online deployment you created. Select the Delete option from the menu. Note: The vertical dots are hidden until you hover over them with your mouse In the subsequent pop up window, click on the Delete button to confirm you want to delete this deployment. You can follow the same process to delete other deployments as needed. Conclusion Congratulations. You've completed this lab and seen how to create and test online deployments for your machine learning models.","title":"Deploying and consuming models"},{"location":"autoai/wml/#machine-learning-model-online-deployment-and-scoring","text":"In this module, we will learn how to deploy our Machine Learning models. By doing so, we make them available for use in production such that applications and business processes can derive insights from them. There are several types of deployments available ( depending on the model framework used ). In this lab, we will explore: Online Deployments - Allows you to run the model on data in real-time, as data is received by a web service. This lab will build an online deployment and test the model endpoint using both the built in testing tool as well as external testing tools. Note: You can click on any image in the instructions below to zoom in and see more details. When you do that just click on your browser's back button to return to the previous page.","title":"Machine Learning Model Online Deployment and Scoring"},{"location":"autoai/wml/#create-online-model-deployment","text":"After a model has been created, saved and promoted to our deployment space, we can proceed to deploying the model. For this section, we will be creating an online deployment. This type of deployment will make an instance of the model available to make predictions in real time via an API. Although we will use the Cloud Pak for Data UI to deploy the model, the same can be done programmatically. Navigate to the left-hand (\u2630) hamburger menu, click on the Deployments section. Click on the Spaces tab and then choose the deployment space you setup previously by clicking on the name of your space. From your deployment space overview, click the Assets tab and in the Models table, find the model name for the model you previously built and now want to create a deployment against. Use your mouse to hover over the right side of that table row and click the Deploy rocket icon (the icons are not visible by default until you hover over them). On the Create a deployment screen, choose Online for the Deployment Type , give the Deployment a name and optionally a description and click the Create button. Click on the Deployments tab. The new deployment status will show as In progress and then switch to Deployed when it is complete.","title":"Create Online Model Deployment"},{"location":"autoai/wml/#test-online-model-deployment","text":"Cloud Pak for Data offers tools to quickly test out Watson Machine Learning models. We begin with the built-in tooling. From the Model deployment page, once the deployment status shows as Deployed , click on the name of your deployment. The deployment API reference tab shows how to use the model using cURL , Java , Javascript , Python , and Scala . To get to the built-in test tool, click on the Test tab and then click on the Provide input data as JSON icon. Copy and paste the following data objects into the Body panel (replace the text that was in the input panel). { \"input_data\": [ { \"fields\": [ \"number\", \"location\", \"u_floor\", \"u_room\", \"category\", \"subcategory\", \"business_service\", \"priority\", \"assignment_group\", \"taskslatable_sla\", \"taskslatable_stage\", \"inc_calendar_duration\", \"taskslatable_schedule\", \"taskslatable_start_time\", \"taskslatable_end_time\" ], \"values\": [ [ \"\", \"530 East 74th (Koch)\", \"16th Floor\", \"16-260\", \"Hardware\", \"Printer\", \"\", \"5 - Planning\", \"\", \"\", \"\", \"8-5 weekdays excluding holidays\", \"\", \"\" ] ] } ] } Click the Predict button. The model will be called with the input data and the results will display in the Result window. Scroll down to the bottom of the result to see the prediction. Note: For some deployed models (for example AutoAI based models), you can provide the request payload using a generated form by clicking on the Provide input using form icon and providing values for the input fields of the form. If the form is not available for the model you deployed, the icon will not be present or will remain grayed out. Important: If you have completed this section and do not plan on completing the other optional deployment approaches below, please go ahead and cleanup your deployment. Follow the Cleanup Deployment instructions below.","title":"Test Online Model Deployment"},{"location":"autoai/wml/#cleanup-deployments","text":"You can clean up the deployments created for your models. To remove the deployment: Navigate to the left-hand (\u2630) hamburger menu, expand the Deployments section and click on View all spaces . Choose the deployment space you setup previously by clicking on the name of your space. From your deployment space overview, click the Assets tab and in the 'Model' table, click on the model name that you previousely promoted and created deployments against. Under 'Deployment Types', click on Online to view the online deployments you have created for this model. In the table on the main panel, click on the three vertical dots at the right of the row for the online deployment you created. Select the Delete option from the menu. Note: The vertical dots are hidden until you hover over them with your mouse In the subsequent pop up window, click on the Delete button to confirm you want to delete this deployment. You can follow the same process to delete other deployments as needed.","title":"Cleanup Deployments"},{"location":"autoai/wml/#conclusion","text":"Congratulations. You've completed this lab and seen how to create and test online deployments for your machine learning models.","title":"Conclusion"},{"location":"jupyter/","text":"Brest Cancer Tumor Classification The objective of this module it to predict the likelihood for a patient getting diagnosed with a malignant form of breast cancer using the attributes of the dataset. About the dataset You can get this data set from this link and is loaded in this project as a Data asset for convenience. This dataset contains 569 samples of malignant and benign tumor samples. The diagnosis column has two values, M represents malignant and B benign tumors. The rest of the columns, 2 to 11, contain 10 real valued features that have been computed from digitized of image cell nuclei.","title":"Introduction"},{"location":"jupyter/#brest-cancer-tumor-classification","text":"The objective of this module it to predict the likelihood for a patient getting diagnosed with a malignant form of breast cancer using the attributes of the dataset.","title":"Brest Cancer Tumor Classification"},{"location":"jupyter/#about-the-dataset","text":"You can get this data set from this link and is loaded in this project as a Data asset for convenience. This dataset contains 569 samples of malignant and benign tumor samples. The diagnosis column has two values, M represents malignant and B benign tumors. The rest of the columns, 2 to 11, contain 10 real valued features that have been computed from digitized of image cell nuclei.","title":"About the dataset"},{"location":"jupyter/image-classification/","text":"Training a model for breast cancer classification using Watson Studio Jupyter notebooks Go the (\u2630) navigation menu, expand Projects and click on the BreastCancerClassification project pre-created for this section. Click on the notebook name breast_cancer_tumor_classification to open it. Let's interactively run the steps included in the notebook. To do so click on the edit button. Run step by step from 1. to 4. to get the data, visualize it, train the model and evaluate its performance.","title":"Running Jupyter notebooks"},{"location":"jupyter/image-classification/#training-a-model-for-breast-cancer-classification-using-watson-studio-jupyter-notebooks","text":"Go the (\u2630) navigation menu, expand Projects and click on the BreastCancerClassification project pre-created for this section. Click on the notebook name breast_cancer_tumor_classification to open it. Let's interactively run the steps included in the notebook. To do so click on the edit button. Run step by step from 1. to 4. to get the data, visualize it, train the model and evaluate its performance.","title":"Training a model for breast cancer classification using Watson Studio Jupyter notebooks"},{"location":"rstudio/","text":"RStudio for unstructured data and Introductory NLP with Cloud Pak for Data Working with R in RStudio within CPD and using examples from Pubmed, an analysis of text with the LDA (Latent Dirichlet Allocation) topic modeling algorithm will be presented by John Cadley and Luke Czapla. This session is accessible to both beginners and experts with the R programming language, through providing code and modifying key terms for the search queries. The visualization of resulting clusters, their importance, and intersection of cluster words within other clusters will then be done in RStudio as well, with a browseable visualization tool. Subtopics and Agenda: Initialization of an RStudio environment with small resource allocation. Syntax for Pubmed queries Processes for returning results using Entrez Direct Running demonstration LDA topic modeling over Pubmed abstracts Additional Topics Document-level clustering with Carrot2, a web interface for clustering any set of documents with cluster topics titles based on any desired key fields. Discussion of STC, Lingo, and Bisecting K-means algorithms. Pre-installed global dependencies For this module, additional had to be pre-installed. To install global packages we used the following command: > install.packages(\"<package-name>\", lib=\"/cc-home/_global_/R\") This is the list of dependencies installed: topicmodels textmineR LDAvis servr tidytext","title":"Introduction"},{"location":"rstudio/#rstudio-for-unstructured-data-and-introductory-nlp-with-cloud-pak-for-data","text":"Working with R in RStudio within CPD and using examples from Pubmed, an analysis of text with the LDA (Latent Dirichlet Allocation) topic modeling algorithm will be presented by John Cadley and Luke Czapla. This session is accessible to both beginners and experts with the R programming language, through providing code and modifying key terms for the search queries. The visualization of resulting clusters, their importance, and intersection of cluster words within other clusters will then be done in RStudio as well, with a browseable visualization tool.","title":"RStudio for unstructured data and Introductory NLP with Cloud Pak for Data"},{"location":"rstudio/#subtopics-and-agenda","text":"Initialization of an RStudio environment with small resource allocation. Syntax for Pubmed queries Processes for returning results using Entrez Direct Running demonstration LDA topic modeling over Pubmed abstracts","title":"Subtopics and Agenda:"},{"location":"rstudio/#additional-topics","text":"Document-level clustering with Carrot2, a web interface for clustering any set of documents with cluster topics titles based on any desired key fields. Discussion of STC, Lingo, and Bisecting K-means algorithms.","title":"Additional Topics"},{"location":"rstudio/#pre-installed-global-dependencies","text":"For this module, additional had to be pre-installed. To install global packages we used the following command: > install.packages(\"<package-name>\", lib=\"/cc-home/_global_/R\") This is the list of dependencies installed: topicmodels textmineR LDAvis servr tidytext","title":"Pre-installed global dependencies"},{"location":"rstudio/topic-modeling/","text":"Running RStudio Go the (\u2630) navigation menu, expand Projects and click on the RStudioPubmedTopicModeling project pre-created for this section. Open RStudio by clicking on Launch IDE and the RStudio . Select runtime RStudio (2 vCPU and 2 GB RAM) and click on Launch button. Once the RStudio is open, click on the project_data_asset directory and click again to open the notebook Sequentially from 1. to 6. run step by step clicking on the play button of each section Load dependencies Fetch articles from Pubmed and persist dataset . If this step fails you can still continue using the pre-loaded dataset. Load and visualize articles dataset Prepare data Run LDA . This can take a couple of minutes. Generate visualization After step 6. successfully completes, you will see a new directory serVis under your Files tab on the lower right side. Click on serVis , then click on the index.html file and select View in Web Browser . A new window will open on your default browser. Feel free to play with the visualization you just generated.","title":"Running RStudio"},{"location":"rstudio/topic-modeling/#running-rstudio","text":"Go the (\u2630) navigation menu, expand Projects and click on the RStudioPubmedTopicModeling project pre-created for this section. Open RStudio by clicking on Launch IDE and the RStudio . Select runtime RStudio (2 vCPU and 2 GB RAM) and click on Launch button. Once the RStudio is open, click on the project_data_asset directory and click again to open the notebook Sequentially from 1. to 6. run step by step clicking on the play button of each section Load dependencies Fetch articles from Pubmed and persist dataset . If this step fails you can still continue using the pre-loaded dataset. Load and visualize articles dataset Prepare data Run LDA . This can take a couple of minutes. Generate visualization After step 6. successfully completes, you will see a new directory serVis under your Files tab on the lower right side. Click on serVis , then click on the index.html file and select View in Web Browser . A new window will open on your default browser. Feel free to play with the visualization you just generated.","title":"Running RStudio"}]}